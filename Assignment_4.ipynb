{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6SDDvmxCeZIc5B+vAwb2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/disha-002/DeepLearning/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RycYQU_Jsnzi",
        "outputId": "fa408822-3691-46ac-a6d4-1df69f5d7b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  experience  income\n",
            "0   25           1   30450\n",
            "1   30           3   35670\n",
            "2   47           2   31580\n",
            "3   32           5   40130\n",
            "4   43          10   47830\n",
            "Index(['age', 'experience', 'income'], dtype='object')\n",
            "(20, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"/content/multiple_linear_regression_dataset.csv\")\n",
        "\n",
        "print(df.head(5))\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# age,experience are inputs\n",
        "# income\n",
        "# our model needs to handle 2 features\n",
        "\n",
        "X=df[[\"age\",\"experience\"]]\n",
        "y=df[\"income\"]\n",
        "\n",
        "# the shape of X is (20,2)\n",
        "#the shape of y is (20,1)\n",
        "'''\n",
        "x is the input variable on the basis o which prediction needs to be made ,\n",
        "there only one prediction that we have to make and hence it has 1 column. Where as y is\n",
        "dependent on two variables and that's why it has 2 columns.\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "DYb1nbsmzDm1",
        "outputId": "8191c714-91d4-4f51-b2eb-402fa2bd7b47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nx is the input variable on the basis o which prediction needs to be made , \\nthere only one prediction that we have to make and hence it has 1 column. Where as y is \\ndependent on two variables and that's why it has 2 columns.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n_features = X.shape[1]\n",
        "\n",
        "w = np.zeros(n_features)\n",
        "b=0.0\n",
        "'''\n",
        "we need one weight per feature because each feauture will affect the target\n",
        "value diffently and hence each feature holds different importance.\n",
        "'''\n",
        "# bias is considered as the offset and is not to do with the importance of the feature\n",
        "\n",
        "# according to me initializing with large values won't be risky because the model is anyways learning and updating it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "m59B8kXV0rib",
        "outputId": "d271ab37-72f4-41bd-95a6-5181fa75689f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwe need one weight per feature because each feauture will affect the target \\nvalue diffently and hence each feature holds different importance.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X,w,b):\n",
        "  y_hat = X.dot(w) + b\n",
        "  return y_hat\n",
        "\n",
        "\n",
        "  #There is no activation function because we are not classifying rather we are predicting a numerical value\n",
        "\n",
        "  # y_hat can take float values\n",
        "\n",
        "  # logistic regression classifies the data and gives a confidence value for the prediction.\n"
      ],
      "metadata": {
        "id": "OP_BTFYF1XSL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def meanSquared_error(y,y_hat):\n",
        "  loss=((y_hat - y)**2).mean()\n",
        "  return loss\n",
        "\n",
        "  # we square the error because it will penalize the large errors and small errors will be neglected\n",
        "\n",
        "  # if one prediction is very wrong , since we average out the error , I guess it won't affect a lot\n",
        "'''\n",
        "  absolute error will take small errors also into consideration , if we take say\n",
        "  1.5 lakhs as income and error is 10 rupees ,this error will also be added when\n",
        "  it is a very small error and does not matter much\n",
        "  '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "OIR-xzoa2HS0",
        "outputId": "4f70386a-4ce9-4993-e21a-dabc2574bde4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  absolute error will take small errors also into consideration , if we take say \\n  1.5 lakhs as income and error is 10 rupees ,this error will also be added when \\n  it is a very small error and does not matter much \\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradients(X,y,y_hat):\n",
        "  N=len(y)\n",
        "\n",
        "  dw=(2/N)* X.T.dot(y_hat -y)\n",
        "  db=(2/N)* (y_hat -y).sum()\n",
        "\n",
        "  return dw,db\n",
        "\n",
        "  '''\n",
        "  the function for prediction of y has x multiplied with w and hence when\n",
        "  differenciating  with w x appears in dw but does not appear in db since b is not multiplied by x\n",
        "  '''\n",
        "\n",
        "  # gradient is the rate of change of error , so we are differentiating the error only with w and b and hence it has error everywhere\n",
        "\n",
        "  # if the error is zero , the prediction is correct and hence no learning happens , weights and biases will not be updated"
      ],
      "metadata": {
        "id": "5bMKp2A03qCs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(w,b,dw,db,lr):\n",
        "  w= w- lr*dw\n",
        "  b= b- lr*db\n",
        "\n",
        "  return w,b"
      ],
      "metadata": {
        "id": "NueodN4i6rDd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr =0.0001\n",
        "epochs=1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  y_hat=predict(X,w,b)\n",
        "  loss = meanSquared_error(y,y_hat)\n",
        "  dw,db=compute_gradients(X,y,y_hat)\n",
        "  w,b = update_parameters(w,b,dw,db,lr)\n",
        "\n",
        "  if(epoch % 100 == 0):\n",
        "    print(f\"Epoch {epoch}, Loss:{loss}\")\n",
        "\n",
        "\n",
        "# yes , loss decreases over time\n",
        "\n",
        "# if it increases , we must adjust the parameters such as learning rate and epochs\n",
        "\n",
        "# learning rate determines te rate of learning of the model after each epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN4v1z-m6_oy",
        "outputId": "3e285bb2-351b-48e9-fbf1-db30be82da2f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss:1727049635.0\n",
            "Epoch 100, Loss:66491868.55311352\n",
            "Epoch 200, Loss:61752567.201190114\n",
            "Epoch 300, Loss:58616531.07847049\n",
            "Epoch 400, Loss:56528801.53951118\n",
            "Epoch 500, Loss:55126542.02946697\n",
            "Epoch 600, Loss:54172526.94885703\n",
            "Epoch 700, Loss:53511656.14292054\n",
            "Epoch 800, Loss:53042523.72795741\n",
            "Epoch 900, Loss:52698829.56325033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"final weight:\\n\",w)\n",
        "print(\"\\n\")\n",
        "print(\"final bias:\\n\",b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnxhbNyl8QlM",
        "outputId": "98c43db1-bdea-4392-fd16-b3c7060fd6e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final weight:\n",
            " age            764.754059\n",
            "experience    1371.034304\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "final bias:\n",
            " 321.73641174472493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_candidate =np.array([68,4.5])\n",
        "predicted_salary=new_candidate.dot(w)+b\n",
        "print(predicted_salary)\n",
        "\n",
        "# no , according to me it is not reasonable\n",
        "# yes, it interpolates smoothly\n",
        "# it is better than threshold rules , since we are predicting income here , we'll have to use a lot of threshold values and also i guess there will be much more errors or they will be hard coded predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2CfGjcA88gT",
        "outputId": "3c527bba-74f3-47e2-f4a3-b08f1c763d66"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58494.66680654775\n"
          ]
        }
      ]
    }
  ]
}